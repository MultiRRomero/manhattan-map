PLANS:

My ATL room: 13' x 11'3" (or 12'9" by 11'2" not including woodwork)

Data sources:
- Craigslist
- Renthop
- NYBits

Craigslist:
- http://newyork.craigslist.org/jsonsearch/nfb/mnh?query=doorman&hasPic=1&nh=121&nh=129&nh=130&nh=139&nh=128&maxAsk=4200&bedrooms=1
- and then resolve cluster:
- http://newyork.craigslist.org/jsonsearch/nfb/mnh?query=doorman&hasPic=1&nh=121&nh=129&nh=130&nh=139&nh=128&maxAsk=4200&bedrooms=1&geocluster=113006708418&key=fhbmFsBQ-JuLz9_UXO4Uuw
- for full page, need to find:
    <section id="postingbody">
    ...
    </section>
    and strip out tags within ...
    and replace multiple newlines with 1 and multiple spaces with 1
    and remove tabs
- missing: SQFT, A/C, Fitness center, elevator -> just do text search?

NYBits:
- missing: fitness, A/C, elevator

Plan:
- Get apartment data
- Get Subway data
- Hard-code subway lines
- Define distance function and filter apartment data to be within distance of subway stops
- Output tab separated txt so can view excel spreadsheet

NEXT STEPS:
xxx 1. Fix timestamp / Add address
2. More sources? Apartments.com?
3. distance function
4. output
5. deploy


Renthop:
- Search page:
  - Title
  - Price
  - posting date ish
  - URL
- Details page:
  - Blurb
  - Lat/long
  - Address
  - Fee

Columns:
- Title
- Price
- URL
- Fee / no fee
- Lat/long
- Posting date
- SQFT
~ A/C
~ Fitness center
~ Elevator
~ Blurb

Database:
- want apartment data table with ID
- want history table to tell when we find an entry and point to apartment data

How this will work:
- when run, need to associate permalink with an item
- if no item, then save the entry

- when create apartment with URL, try to fill with DB
- have function has_full_data + save_full_data
- have separate script to call all data sources and save transactions

http://www.brickunderground.com/blog/2012/01/8_best_websites_for_finding_a_no_fee_apt_in_new_york_city

TODO for spreadsheet:
xx- renthop timestamp instead of date
xx- blurbs are huge
xx- distance in meters



TO GET BROKERS:
1. get all URLs
2. modify classes to print_broker for list of URLs
3. STOP CRON
4. add to spreadsheet manually
5. update program to expect that column - both output to it for new listings && adjust annotations column
6. START CRON

- OR -
update to DB when don't have the broker


DATA TODO: 
- filter renthop by price
- remove featured=1 from streeteasy

Spreadsheets:
- Have 5 sheets: unprocessed, acceptible, bad, impossible, dups
- We manually move stuff between sheets
- Sheets actions:
  - write new rows -> to unprocessed
    - Need list of all URLs across sheets to do diff
    - Need size of sheet 0 to know where to write
  - update seen time -> to all sheets
    - Just iterate over all cells, need new data indexed by URL
  - store annotations -> from all sheets
    - Iterate over all data
-> on iteration, do those actions to all sheets
- need:
  - url-keyed new data
  - need listing of all data to process what's new data
    - for this, can temp index
  

